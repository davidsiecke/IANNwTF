{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Multi-Layer Perceptron"
      ],
      "metadata": {
        "id": "FUkVCsvIaU52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Data"
      ],
      "metadata": {
        "id": "HvTxCs4vagC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset"
      ],
      "metadata": {
        "id": "cYR55Ym4cEwe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5KGWArv-XWVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb8f9cd-0a0c-4741-b014-fd3516a87d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = datasets.load_digits(return_X_y=True)\n",
        "(inputs, targets) = data\n",
        "\n",
        "print(targets[0:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting first two images in the dataset"
      ],
      "metadata": {
        "id": "qRRxxU1ecLTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input0_plotting = inputs[0].reshape(8,8)\n",
        "input1_plotting = inputs[1].reshape(8,8)\n",
        "\n",
        "# first image in the dataset\n",
        "fig0, ax0 = plt.subplots()\n",
        "ax0.matshow(input0_plotting, cmap=\"Greys\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "j4IdgxN0Y2Ve",
        "outputId": "d8cd2857-8215-48b7-d57d-c8a8a1ad8a11"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# second image in the dataset\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.matshow(input1_plotting, cmap=\"Greys\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "ROX8eGYTd_U0",
        "outputId": "69217e91-bc7b-4934-f17d-f69cac2ed0e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape images to shape (64)"
      ],
      "metadata": {
        "id": "Ej9vXV5rhJaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs[0].shape\n",
        "# we see that the images already have shape (64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY8sr0DOhffZ",
        "outputId": "818d8bd3-c9a2-4d8d-b5b1-aed62c85cd8d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure the images are represented as float32 values within either [0 to 1] or [-1 to 1] range"
      ],
      "metadata": {
        "id": "YxKv7a-Ce6EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(inputs[0,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r_iCeRkfFGL",
        "outputId": "6fd7e84f-ffc9-4703-c0a1-34841a4c88e1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# as pixel values seem to be represented as float64 values, we cast them to float32 values.\n",
        "inputs = inputs.astype(\"float32\")"
      ],
      "metadata": {
        "id": "bf6ldXEHhF9F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.min(inputs), np.max(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUuXW8b3lmmA",
        "outputId": "ab6f37d3-3104-47a8-8387-b080fada0075"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we see that the minimum is fine, but the maximum is >1, so we rescale the\n",
        "# inputs to range [0 to 1]\n",
        "inputs = (inputs-np.min(inputs))/(np.max(inputs)-np.min(inputs))"
      ],
      "metadata": {
        "id": "fKhnCa2KmeuE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-hot encode the target digits (e.g. the target digit 2 would be represented as [0,0,1,0,0,0,0,0,0,0], 9 as [0,0,0,0,0,0,0,0,0,9]). Onehot encoded vectors should have the shape (10) or (1,10) up to your preference"
      ],
      "metadata": {
        "id": "aer3oBEloGHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hots = np.eye(N=10)\n",
        "targets_oh = np.array(list(map(lambda target: one_hots[target], targets)))"
      ],
      "metadata": {
        "id": "VvkvZKGYoSbl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a generator function, which shuffles the (input, target) pairs (keeping the respective input and target together).\n",
        "\n",
        "Adjust your generator function to create minibatches."
      ],
      "metadata": {
        "id": "6qD0iMm2cSws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_and_batch_data(inputs, targets, minibatch_size):\n",
        "    # create an index vector\n",
        "    indices = np.arange(len(inputs))\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # shuffle inputs and targets\n",
        "    shuffled_inputs = inputs[indices]\n",
        "    shuffled_targets = targets[indices]\n",
        "\n",
        "    # calculate the number of minibatches\n",
        "    num_minibatches = len(inputs) // minibatch_size\n",
        "\n",
        "    for i in range(num_minibatches):\n",
        "      # calculate the indices delimiting the current minibatch\n",
        "      start_idx = i * minibatch_size\n",
        "      end_idx = (i + 1) * minibatch_size\n",
        "\n",
        "      # bundle training examples into minibatches\n",
        "      minibatch_inputs = shuffled_inputs[start_idx:end_idx]\n",
        "      minibatch_targets = shuffled_targets[start_idx:end_idx]\n",
        "\n",
        "      yield minibatch_inputs, minibatch_targets"
      ],
      "metadata": {
        "id": "kQ9YMLwxyIHg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Sigmoid Activation Function\n",
        "\n",
        "Implement the Sigmoid Activation Function as an object with a call function (we will later add a backwards function for backpropagation, this being the reason its implemented as an object). It should expect inputs as ndarrays of shape minibatchsize, num units."
      ],
      "metadata": {
        "id": "4hE-nUl22br8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid():\n",
        "  def __call__(self, pre_act):\n",
        "    return np.exp(pre_act) / (1 + np.exp(pre_act))"
      ],
      "metadata": {
        "id": "5Z46-rNq2bVR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Softmax Activation Function\n",
        "Implement the the softmax in Numpy, again as an object with a call function, which expects inputs of size minibatchsize,10 [because there are 10 neurons in the output layer], where each 1,10 subelement represents a vector as discussed above"
      ],
      "metadata": {
        "id": "NvdQjCyIMHGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax():\n",
        "\n",
        "    def __call__(self, pre_acts):\n",
        "\n",
        "        # for each of the samples in the minibatch the sum of the preactivations of the last layer has to be calculated, so axis=1 since per row\n",
        "        sum_of_preactivations = pre_acts.sum(axis=1).reshape(pre_acts.shape[0],1) # shape = (minibatchsize,1)\n",
        "\n",
        "        list_outputs=[]\n",
        "        # each output of each sample in the minibatch is divided by the sum of all outputs in their sample and stored in a list\n",
        "        for z_i, sum_z_j in zip(pre_acts, sum_of_preactivations):\n",
        "            list_outputs.append(z_i/sum_z_j)\n",
        "\n",
        "        activations = np.array(list_outputs).reshape(pre_acts.shape)\n",
        "        return activations"
      ],
      "metadata": {
        "id": "lOUvfh79LETT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Weights\n",
        "\n",
        "Implement a class representing an MLP layer. The constructor should specify the activation function (Sigmoid or Softmax as implemented above), as well as the number of units (Perceptrons) in this layer, and the input size (number of units in the preceding layer). It should create attributes for the weight matrix and a bias vector (or absorb the bias vector into the weight matrix as discussed in the lecture, depending on your preference). Initialize the weights as small random values (e.g. from a normal distribution with μ = 0., σ = 0.2), and bias values set to zero.\n",
        "Implement a forward function, which accepts an input of shape minibatchsize, input size, and outputs an ndarray of shape minibatchsize,num units after applying the\n",
        "weight matrix, the bias and the activation function."
      ],
      "metadata": {
        "id": "1MJg7V4rZZXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer():\n",
        "\n",
        "  def __init__(self, layer_size, input_size, act_func):\n",
        "    self.layer_size = layer_size\n",
        "    self.input_size = input_size\n",
        "    self.act_func = act_func\n",
        "\n",
        "    self.weights = np.random.normal(0., 0.2, size=(self.input_size, self.layer_size))\n",
        "    self.biases = np.zeros((1,self.layer_size))\n",
        "\n",
        "    self.activation_prevL = None # value set in __call__(); used in backwards()\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    self.activation_prevL = inputs\n",
        "    return inputs@self.weights + self.biases   # this is the preactivation"
      ],
      "metadata": {
        "id": "UeVGWcDeZmqt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Putting together the MLP\n",
        "\n",
        "Implement a class representing a full MLP. You should be able to specify the number of layers, as well as the size of each layer separately in the constructor. Remember the initial input will be shaped minibatchsize,64, the final output will be shaped minibatchsize, 10. The MLP should have an attribute, which is a list of all the MLP layers it contains.\n"
      ],
      "metadata": {
        "id": "PwQPx1YXlc75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP():\n",
        "\n",
        "  def __init__(self, number_layers, input_layer_size, layer_sizes):\n",
        "    self.number_layers = number_layers\n",
        "    self.layer_sizes = layer_sizes\n",
        "\n",
        "    self.preactivations = [] # populated in call(), used in backwards()\n",
        "    self.activations = [] # populated in call(), used in backwards()\n",
        "    self.losses = [] # populated and used in backwards()\n",
        "\n",
        "    layers_list = []\n",
        "    for i in range(self.number_layers):\n",
        "      # input size is the size of the previous layer. this holds for all layers except for the first, where the size of the previous layer is the input size.\n",
        "      if (i == 0):\n",
        "        number_inputs = input_layer_size\n",
        "      else:\n",
        "        number_inputs = layer_sizes[i-1]\n",
        "      # activation function is Sigmoid for all layers except for the last, where it is Softmax\n",
        "      if (i == self.number_layers-1):\n",
        "        act_function = Softmax()\n",
        "      else:\n",
        "        act_function = Sigmoid()\n",
        "      layers_list.append(\n",
        "        Layer(\n",
        "          layer_size = layer_sizes[i],\n",
        "          input_size = number_inputs,\n",
        "          act_func = act_function\n",
        "        )\n",
        "      )\n",
        "    self.layers = layers_list\n",
        "\n",
        "  def __call__(self, input):\n",
        "    for i, layer in enumerate(self.layers):\n",
        "      preactivation = layer(self.activations[i-1] if i>0 else input)\n",
        "      self.preactivations.append(preactivation)\n",
        "      self.activations.append(layer.act_func(preactivation))\n",
        "    return self.activations[-1]"
      ],
      "metadata": {
        "id": "xp23M6RrQz22"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6 CCE Loss Function\n",
        "\n",
        "Implement a categorical cross-entropy loss function for your network. Again, implement it as an object with a call function for the function itself (which again is extended with a backwards function later)."
      ],
      "metadata": {
        "id": "yq8uPGfwxyOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CCE_Loss():\n",
        "  def __call__(self, prediction, target):\n",
        "    # first, since ln(x) is undefined for negative x, we need to turn negative activation values in the output layer into positive values while retaining the original activation values' distance to the corresponding target\n",
        "    for j, training_example in enumerate(prediction):  # go through all training examples in the minibatch\n",
        "      for i, activation in enumerate(training_example): # go through all output neuron activations the MLP produced for the current training example\n",
        "        if activation < 0:\n",
        "          training_example[i] = target[j,i]+np.abs(target[j,i]+activation)\n",
        "\n",
        "    return -np.sum(target * np.log(prediction), axis=1) # this returns a plain number for each minibatch (ie, an array of shape (minibatch_size,))."
      ],
      "metadata": {
        "id": "cDoDPeR1ykpb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "-1TO99FZsfuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_layers = 2\n",
        "input_layer_size = 64\n",
        "layers_sizes = [10, 10]\n",
        "test = MLP(number_layers, input_layer_size, layers_sizes)\n",
        "\n",
        "minibatch_size = 2\n",
        "test_output = test(inputs[0:minibatch_size])"
      ],
      "metadata": {
        "id": "e1mlF08nsmqB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_output.shape == (minibatch_size, 10))\n",
        "test_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR5gJL5du7HH",
        "outputId": "dd640d31-57d9-433d-ce4e-af1ef8408889"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.03167827, -7.30477917,  1.21507944,  2.71649263,  4.87067585,\n",
              "         6.3185848 , -2.85777045,  3.17683445, -4.62555203, -2.54124379],\n",
              "       [ 0.32006645, -1.84317855,  0.14510835,  0.60646536,  0.86617059,\n",
              "         1.67858057, -0.43167617,  0.84455669, -0.71878625, -0.46730703]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(targets_oh[0:minibatch_size])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odZUxZPeufeI",
        "outputId": "f32bd0f3-96a7-4ec4-f675-bb5886f9e3f7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_loss = CCE_Loss()\n",
        "test_loss = compute_loss(prediction=test_output, target=targets_oh[0:minibatch_size])"
      ],
      "metadata": {
        "id": "r39Sraletxrx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Backpropagation"
      ],
      "metadata": {
        "id": "Y9KjmJxM2ciL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 CCE – Backwards"
      ],
      "metadata": {
        "id": "CAjRt_Mnoikm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backwards(self, y_hat, target):\n",
        "  # y_hat, prediction, shape: (minibatchsize, 10)\n",
        "  # target, shape: (minibatchsize, 10)\n",
        "  # return: error signal, shape: (minibatchsize, 10)\n",
        "  #         containing values of error signal dL_CCE/dy_hat_i for each sample in the minibatch\n",
        "  dL_dyhat = target / (np.log(2)*y_hat)\n",
        "\n",
        "  return dL_dyhat # error signal, shape: (minibatchsize, 10)\n",
        "\n",
        "CCE_Loss.backwards = backwards"
      ],
      "metadata": {
        "id": "hZLnPiterBWp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Sigmoid – Backwards"
      ],
      "metadata": {
        "id": "pEaXtRWUkMOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_dash(self, x): # d a / d pre_a\n",
        "  return self.call(x) * (1 - self.call(x))\n",
        "\n",
        "def backwards(self, prea, dL_da): # dL_da = error signal up to this point in the ANN from the back\n",
        "\n",
        "  #  for all samples of the minibatch calculating d a / d pre_a\n",
        "  da_dprea = self.sigmoid_dash(prea)\n",
        "\n",
        "  # calculating d L / d pre_a\n",
        "  # by using the two partial derivatives: d L / d a and d a / d pre_a\n",
        "  # for each sample for each unit the partial derivatives have to be multiplied separately\n",
        "  dL_dprea = dL_da * da_dprea # matrices of same shape: multiplication of values at same position\n",
        "\n",
        "  # for each of the samples in the minibatch (one sample per row)\n",
        "  # in the columns are the error signals up to the preactivations of this layers units\n",
        "  # (column 1: preactivation error signal for unit 1)\n",
        "  return dL_dprea # shape: (minibatchsize, num_units)\n",
        "\n",
        "Sigmoid.sigmoid_dash = sigmoid_dash\n",
        "Sigmoid.backwards = backwards"
      ],
      "metadata": {
        "id": "fSSGpRaCtSGY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Weights – Backwards"
      ],
      "metadata": {
        "id": "U9fWLM21lQ_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_backwards(self, dL_dprea, prea):\n",
        "  # dL_dprea shape : (minibatchsize, num_units_currentL)\n",
        "  # prea shape : (minibatchsize, num_units_currentL)\n",
        "\n",
        "  num_units_prevL = self.input_size\n",
        "\n",
        "  # derivating the input of each units preactivation in the current layer with respect to each previous layer unit's activation\n",
        "  # thats just the weight matrix bc all other weights cut out when derivating bc they are constants\n",
        "  # -> how does the preactivation change with respect to the activation of the pervious layer\n",
        "  dprea_daprevL = self.weights # shape = (num_units_currentL, num_units_prevL)\n",
        "\n",
        "  # (minibatchsize, num_units_prevL) = (minibatchsize, num_units_currentL) @ (num_units_currentL, num_units_prevL)\n",
        "  # first to return\n",
        "  dL_daprevL = dL_dprea @ dprea_daprevL\n",
        "\n",
        "\n",
        "  a_prevL = self.activation_prevL # shape = (minibatchsize, inputsize)\n",
        "  dprea_dW = a_prevL\n",
        "\n",
        "  # second to return\n",
        "  dL_dW = dL_dprea @ dprea_dW\n",
        "\n",
        "  return (dL_daprevL, dL_dW)\n",
        "\n",
        "Layer.weights_backwards = weights_backwards"
      ],
      "metadata": {
        "id": "ipduIx4ylZ3t"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Layer backwards"
      ],
      "metadata": {
        "id": "XF2bx9p4p-B2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backwards(self, layer_output, derivatives):\n",
        "  my_sigmoid = Sigmoid()\n",
        "  return self.weights_backwards(my_sigmoid.backwards(self.preactivations, derivatives[-1]))\n",
        "\n",
        "Layer.backwards = backwards"
      ],
      "metadata": {
        "id": "wVyXAVgvqG_8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 Gradient Tape and MLP Backwards"
      ],
      "metadata": {
        "id": "IfT33_R8o5Ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backwards(self, targets):\n",
        "  # first of all, we need to compute the CCE loss\n",
        "  minibatch_size = self.activations[-1].shape[0]\n",
        "  compute_loss = CCE_Loss()\n",
        "  self.losses.append(compute_loss(prediction=self.activations[-1], target=targets_oh[0:minibatch_size]))\n",
        "\n",
        "  # now we can do the backwards steps\n",
        "  derivatives = [\"empty\"] * (self.number_layers+1) # +1 since last spot is reserved for CCE derivative\n",
        "\n",
        "  derivatives[-1] = CCE_Loss.backwards(self=compute_loss, y_hat=self.activations[-1], target=targets[-1])\n",
        "\n",
        "  for i in range(self.number_layers):\n",
        "    idx = self.number_layers-1 - i # backwards indexing\n",
        "    derivatives[idx-1] = self.layers[idx].backwards(self.activations[idx], derivatives)\n",
        "\n",
        "  return derivatives\n",
        "\n",
        "MLP.backwards = backwards"
      ],
      "metadata": {
        "id": "I3PFQLgppVH4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.6 Training"
      ],
      "metadata": {
        "id": "I8pwEMKU0fxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training(mlp, inputs, targets, num_epochs, minibatch_size, learning_rate):\n",
        "    num_minibatches = len(inputs) // minibatch_size\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      for i in range(num_minibatches):\n",
        "        # calculate the indices delimiting the current minibatch\n",
        "        start_idx = i * minibatch_size\n",
        "        end_idx = (i + 1) * minibatch_size\n",
        "\n",
        "        mlp(inputs[start_idx:end_idx]) # all relevant data is stored in internal attributes\n",
        "\n",
        "      # backwards step\n",
        "      derivatives = mlp.backwards(targets)\n",
        "\n",
        "      # update weights\n",
        "      W = learning_rate * np.subtract(W, derivatives[:-1])\n",
        "\n",
        "\n",
        "number_layers = 2\n",
        "input_layer_size = 64\n",
        "layer_sizes = [10, 10]\n",
        "\n",
        "num_epochs = 5\n",
        "minibatch_size = 30\n",
        "learning_rate = 0.2\n",
        "\n",
        "my_mlp = MLP(number_layers, input_layer_size, layer_sizes)\n",
        "training(my_mlp, inputs, targets_oh, num_epochs, minibatch_size, learning_rate)\n",
        "\n",
        "avg_losses = []\n",
        "for i in range(num_epochs):\n",
        "  start_idx = i * num_epochs\n",
        "  end_idx = (i + 1) * num_epochs\n",
        "  avg_losses.append(np.mean(my_mlp.losses[start_idx:end_idx]))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(np.array(list(range(num_epochs))), np.array(avg_losses))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "OWye7Vij0ib9",
        "outputId": "ddec0171-72f1-491b-9846-f721d1588a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-215-036982e1aecf>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmy_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_layer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mavg_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-215-036982e1aecf>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(mlp, inputs, targets, num_epochs, minibatch_size, learning_rate)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0;31m# backwards step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mderivatives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-214-e0a94c0b8846>\u001b[0m in \u001b[0;36mbackwards\u001b[0;34m(self, targets)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_layers\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m \u001b[0;31m# backwards indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mderivatives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderivatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mderivatives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-213-57fb98a42eb6>\u001b[0m in \u001b[0;36mbackwards\u001b[0;34m(self, layer_output, derivatives)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbackwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderivatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmy_sigmoid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_sigmoid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderivatives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackwards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackwards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Layer' object has no attribute 'preactivations'"
          ]
        }
      ]
    }
  ]
}